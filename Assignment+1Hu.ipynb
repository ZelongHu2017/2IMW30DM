{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of Data Mining: Assignment 1\n",
    "\n",
    "Please complete all assignments in this notebook. You should submit this notebook, as well as a PDF version (See File > Download as)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from preamble import *\n",
    "plt.rcParams['savefig.dpi'] = 100\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handwritten digit recognition (5 points, 1+2+2)\n",
    "The [MNIST dataset](https://www.openml.org/d/554) contains 70,000 images of handwritten digits (0-9) represented by 28 by 28 pixel values. We can easily download it from OpenML and visualize one of the examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is a temporary read-only OpenML key. Replace with your own key later. \n",
    "oml.config.apikey = '9aa79acf0397989f8e53b2d854deaa61'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x110029630>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 3\n"
     ]
    },
    {
     "data": {
      "application/pdf": "JVBERi0xLjQKJazcIKu6CjEgMCBvYmoKPDwgL1R5cGUgL0NhdGFsb2cgL1BhZ2VzIDIgMCBSID4+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\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAFdCAYAAAA9hbc/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8waoNZ99MQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x102684550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_data = oml.datasets.get_dataset(554) # Download MNIST data\n",
    "X, y = mnist_data.get_data(target=mnist_data.default_target_attribute); # Get the predictors X and the labels y\n",
    "plt.imshow(X[10].reshape(28, 28), cmap=plt.cm.gray_r) # Take the first example, reshape to a 28x28 image and plot\n",
    "print(\"Class label:\",y[10]) # Print the correct class label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate a k-Nearest Neighbor classifier with its default settings.\n",
    "    - Use the first 60,000 examples as the training set and the last 10,000 as the test set\n",
    "    - What is the predictive accuracy?\n",
    "    - Find a few misclassifications, and plot them together with the true labels (as above). Are these images really hard to classify?\n",
    "- Optimize the value for the number of neighbors $k$ (keep $k$ < 50) on a stratified subsample (e.g. 10%) of the data\n",
    "    - Use 10-fold crossvalidation and plot $k$ against the misclassification rate. Which value of $k$ should you pick?\n",
    "    - Do the same but with 100 bootstrapping repeats. Are the results different? Explain.\n",
    "- Compare kNN against the linear classification models that we have covered in the course (logistic regression and linear SVMs).\n",
    "    - First use the default hyperparameter settings.\n",
    "    - Next, optimize for the degree of regularization ($C$) and choice of penalty (L1/L2). Again, plot the accuracy while increasing the degree of regularization for different penalties. Interpret the results. \n",
    "    - Report is the optimal performance. Can you get better results than kNN?\n",
    "    \n",
    "Report all results clearly and interpret the results.  \n",
    "Note: while prototyping/bugfixing, you can speed up experiments by taking a smaller sample of the data, but report your results as indicated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Zelong/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([6, 9, 1, ..., 7, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 784), dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a temporary read-only OpenML key. Replace with your own key later. \n",
    "oml.config.apikey = '9aa79acf0397989f8e53b2d854deaa61'\n",
    "mnist_data = oml.datasets.get_dataset(554) # Download MNIST data\n",
    "\n",
    "from sklearn import cross_validation\n",
    "\n",
    "X, y = mnist_data.get_data(target=mnist_data.default_target_attribute); # Get the predictors X and the labels y\n",
    "\n",
    "# load dataset and partition in training and testing sets\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, random_state=0)\n",
    "\n",
    "X_train  [0:60000]\n",
    "y_train  [0:60000]\n",
    "X_test   [60000:70000]\n",
    "y_test   [60000:70000]\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Test set accuracy: %.2f\" % knn.score(X_test, y_test))\n",
    "#print(\"Misclassification rate of {} is {}\".format(model.__name__, 1-knn.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oml.config.apikey = '9aa79acf0397989f8e53b2d854deaa61'\n",
    "mnist_data = oml.datasets.get_dataset(554) # Download MNIST data\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "X, y = mnist_data.get_data(target=mnist_data.default_target_attribute); # Get the predictors X and the labels y\n",
    "\n",
    "# load dataset and partition in training and testing sets\n",
    "X_sample, _, y_sample, _ = cross_validation.train_test_split(X, y, train_size=0.01,stratify=y)\n",
    "\n",
    "cv_scores = []\n",
    "\n",
    "# creating odd list of K for KNN\n",
    "List = list(range(1,50))\n",
    "\n",
    "#neighbors = filter(lambda x: x > 0, List) \n",
    "\n",
    "\n",
    "for i in List:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    shuffle_split = ShuffleSplit(test_size=.66, train_size=.34, n_splits=100)\n",
    "    scores = cross_val_score(knn, X_sample, y_sample, cv= shuffle_split, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "# changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "# plot misclassification error vs k\n",
    "plt.plot(List, MSE)\n",
    "plt.xlabel('Number of Neighbors K')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.show()\n",
    "\n",
    "# determining best k\n",
    "optimal_k = List[MSE.index(min(MSE))]\n",
    "print (\"The optimal number of neighbors is %d\" % optimal_k)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oml.config.apikey = '9aa79acf0397989f8e53b2d854deaa61'\n",
    "mnist_data = oml.datasets.get_dataset(554) # Download MNIST data\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "X, y = mnist_data.get_data(target=mnist_data.default_target_attribute); # Get the predictors X and the labels y\n",
    "\n",
    "# load dataset and partition in training and testing sets\n",
    "X_sample, _, y_sample, _ = cross_validation.train_test_split(X, y, train_size=0.01,stratify=y)\n",
    "\n",
    "cv_scores = []\n",
    "\n",
    "# creating odd list of K for KNN\n",
    "List = list(range(1,50))\n",
    "\n",
    "#neighbors = filter(lambda x: x > 0, List) \n",
    "\n",
    "\n",
    "for i in List:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    scores = cross_val_score(knn, X_sample, y_sample, cv= 10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "# changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "# plot misclassification error vs k\n",
    "plt.plot(List, MSE)\n",
    "plt.xlabel('Number of Neighbors K')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a temporary read-only OpenML key. Replace with your own key later. \n",
    "oml.config.apikey = '9aa79acf0397989f8e53b2d854deaa61'\n",
    "mnist_data = oml.datasets.get_dataset(554) # Download MNIST data\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X, y = mnist_data.get_data(target=mnist_data.default_target_attribute); # Get the predictors X and the labels y\n",
    "# load dataset and partition in training and testing sets\n",
    "X_sample, _, y_sample, _ = cross_validation.train_test_split(X, y, train_size=0.01,stratify=y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X_sample, y_sample, random_state=0)\n",
    "print(\"Size of training set: {}   size of test set: {}\".format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "#First use the default hyperparameter settings.\n",
    "for model in [LinearSVC(), LogisticRegression()]:\n",
    "    models = model\n",
    "    models.fit(X_train, y_train)\n",
    "    print(\"Misclassification rate of {} is {}\".format(model.__name__, 1-models.score(X_test, y_test)))\n",
    "\n",
    "    \n",
    "#Next, optimize for the degree of regularization ( C ) and choice of penalty (L1/L2). \n",
    "#Again, plot the accuracy while increasing the degree of regularization for different penalties. Interpret the results.\n",
    "LinearSVCList =[]\n",
    "LogisticRegressionList = []\n",
    "\n",
    "for DifferentModel in [LinearSVC, LogisticRegression]:\n",
    "     for C in [0.001,0.01,0.1, 1,10, 100,1000]:\n",
    "            for penalty in [\"L1\", \"L2\"]:\n",
    "            model = DifferentModel(C=C, penalty=penalty, dual=False);\n",
    "            clf = model.fit(X_train, y_train)\n",
    "            if DifferentModel==LinearSVC:\n",
    "                LinearSVCList.append(model.score(X_test, y_test))\n",
    "            else:\n",
    "                LogisticRegressionList.append(model.score(X_test, y_test))\n",
    "SVCscore=np.transpose(np.array(SVC).reshape(7,2))\n",
    "LRscore=np.transpose(np.array(LR).reshape(7,2)) \n",
    "Value_C =[1,2,3,4,5,6,7]\n",
    "\n",
    "plt.plot(Value_C, SVCscore[0], label=\" Penalty L1 with LinearSVC\")\n",
    "plt.plot(Value_C, SVCscore[1], label=\" Penalty L2 with LinearSVC\")\n",
    "plt.plot(Value_C, LRscore[0],  label=\" Penalty L1 with LogisticRegression \")\n",
    "plt.plot(Value_C, LRscore[1],  label=\" Penalty L2 with LogisticRegression \")\n",
    "plt.xticks(Value_C, (0.001,0.01,0.1, 1,10, 100,1000))\n",
    "plt.ylabel(\"Accuracy \")\n",
    "plt.xlabel(\"Value C\")\n",
    "_ = plt.legend()\n",
    "plt.show()\n",
    "                \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection (4 points (2+2))\n",
    "Study how RandomForest hyperparameters interact on the Ionosphere dataset (OpenML ID 59).\n",
    "\n",
    "- Optimize a RandomForest, varying both $n\\_estimators$ and $max\\_features$ at the same time. Use a nested cross-validation and a grid search (or random search) over the possible values, and measure the AUC. Explore how fine-grained this grid/random search can be, given your computational resources. What is the optimal AUC performance you find?\n",
    "- Again, vary both hyperparameters, but this time use a grid search and visualize the results as a plot (heatmap) $n\\_estimators \\times max\\_features \\rightarrow AUC$ with AUC visualized as the color of the data point. Try to make the grid as fine as possible. Interpret the results. Can you explain your observations? What did you learn about tuning RandomForests?\n",
    "\n",
    "Hint: Running this experiment can take a while, so start early and use a feasible grid/random search. Start with a coarse grid or few random search iterations.\n",
    "Hint: Use a log scale (1,2,4,8,16,...) for $n\\_estimators$. Vary $max\\_features$ linearly between 1 and the total number of features. Note that, if you give $max\\_features$ a float value, it will use it as [the percentage of the total number of features](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ionosphere = oml.datasets.get_dataset(59) # Download Ionosphere data\n",
    "X, y = ionosphere.get_data(target=ionosphere.default_target_attribute); # Get the predictors X and the labels y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree heuristics (1 point)\n",
    "Consider the toy training set created below. It predicts whether your date agrees to go out with you depending on the weather.\n",
    "\n",
    "Learn a decision tree:\n",
    "\n",
    "- Implement functions to calculate entropy and information gain\n",
    "- What is the class entropy for the entire dataset? What is the information gain when you split the data using the *Water* feature?\n",
    "- Implement a basic decision tree:\n",
    "    - Select a feature to split on according to its information gain. If multiple features are equally good, select the leftmost one.\n",
    "    - Split the data and repeat until the tree is complete.\n",
    "    - Print out the results (nodes and splits).\n",
    "- Now train a scikit-learn decision tree on the same data. Do you get the same result? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sky</th>\n",
       "      <th>AirTemp</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Water</th>\n",
       "      <th>Forecast</th>\n",
       "      <th>Date?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sunny</td>\n",
       "      <td>warm</td>\n",
       "      <td>normal</td>\n",
       "      <td>strong</td>\n",
       "      <td>warm</td>\n",
       "      <td>same</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sunny</td>\n",
       "      <td>warm</td>\n",
       "      <td>high</td>\n",
       "      <td>strong</td>\n",
       "      <td>warm</td>\n",
       "      <td>same</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rainy</td>\n",
       "      <td>warm</td>\n",
       "      <td>high</td>\n",
       "      <td>strong</td>\n",
       "      <td>cool</td>\n",
       "      <td>change</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sunny</td>\n",
       "      <td>cold</td>\n",
       "      <td>high</td>\n",
       "      <td>strong</td>\n",
       "      <td>warm</td>\n",
       "      <td>change</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sunny</td>\n",
       "      <td>warm</td>\n",
       "      <td>normal</td>\n",
       "      <td>weak</td>\n",
       "      <td>warm</td>\n",
       "      <td>same</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sky AirTemp Humidity    Wind Water Forecast Date?\n",
       "0  sunny    warm   normal  strong  warm     same   yes\n",
       "1  sunny    warm     high  strong  warm     same   yes\n",
       "2  rainy    warm     high  strong  cool   change    no\n",
       "3  sunny    cold     high  strong  warm   change   yes\n",
       "4  sunny    warm   normal    weak  warm     same    no"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Sky\":['sunny','sunny','rainy','sunny','sunny'],\n",
    "                   \"AirTemp\":['warm','warm','warm','cold','warm'],\n",
    "                   \"Humidity\":['normal','high','high','high','normal'],\n",
    "                   \"Wind\":['strong','strong','strong','strong','weak'],\n",
    "                   \"Water\":['warm','warm','cool','warm','warm'],\n",
    "                   \"Forecast\":['same','same','change','change','same'],\n",
    "                   \"Date?\":['yes','yes','no','yes','no']\n",
    "                   });\n",
    "df = df[['Sky', 'AirTemp', 'Humidity', 'Wind', 'Water', 'Forecast', 'Date?']] # Fix column ordering\n",
    "df # print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Complete these functions first\n",
    "def entropy(pos, neg):\n",
    "    return 0\n",
    "\n",
    "def info_gain(pos1,neg1,pos2,neg2):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests (4 points (1+1+2))\n",
    "Study the effect of the number of trees in a RandomForest on the EEG-eye-state dataset (http://www.openml.org/d/1471). This dataset measures brain activity using 15 sensors, and you need to predict whether the person's eyes are open or closed. \n",
    "\n",
    "* Train a RandomForest classifier on this dataset with an increasing number of trees (on a log scale as above). Plot the Out-Of-Bag error against the number of trees.\n",
    "    - The Out-Of-Bag error is the test error obtained when using bootstrapping, and using the non-drawn data points as the test set. This is what a RandomForest does internally, so you can retrieve it from the classifier. The code below hints on how to do this.\n",
    "* Construct the same plot, but now use 10-fold Cross-validation and error rate instead of the OOB error. Compare the two. What do you learn from this?\n",
    "* Compare the performance of the RandomForest ensemble with that of a single full decision tree. Compute the AUC as well as the bias and variance. Does the bias and variance increase/decrease for the ensemble? Does the number of trees affect the result?\n",
    "\n",
    "Hint: Error rate = 1 - accuracy  \n",
    "Hint: We discussed bias-variance decomposition in class. It is not included in scikit-learn, so you'll need to implement it yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg = oml.datasets.get_dataset(1471) # Download Ionosphere data\n",
    "X, y = eeg.get_data(target=eeg.default_target_attribute);\n",
    "\n",
    "# Out of bag errors can be retrieved from the RandomForest classifier. You'll need to loop over the number of trees.\n",
    "# http://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html\n",
    "from sklearn import ensemble\n",
    "clf = ensemble.RandomForestClassifier()\n",
    "clf.fit(X, y)\n",
    "(1 - clf.oob_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A regression benchmark (1 point)\n",
    "Consider the liver-disorder dataset (http://www.openml.org/d/8). The goal is to predict how much alcohol someone consumed based on blood test values.\n",
    "\n",
    "- Take a selection of the algorithms that we covered in class that can do regression.\n",
    "- Based on what you learned in the previous exercises, make educated guesses about good hyperparameter values and set up a grid or random search.\n",
    "- Evaluate all models with 10-fold cross-validation and root mean squared error (RMSE). Report all results. Which model yields the best results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "liver = oml.datasets.get_dataset(8) # Download Liver-disorders data\n",
    "X, y = liver.get_data(target=liver.default_target_attribute);"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
